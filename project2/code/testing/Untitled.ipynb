{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('../data/conv_cases.pkl', 'rb') as conv_f, \\\n",
    "             open('../data/max_pool_cases.pkl', 'rb') as max_pool_f, \\\n",
    "             open('../data/fc_cases.pkl', 'rb') as fc_f:\n",
    "            conv_cases = pickle.load(conv_f)\n",
    "            max_pool_cases = pickle.load(max_pool_f)\n",
    "            fc_cases = pickle.load(fc_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"All the layer functions go here.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function, absolute_import\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class FullyConnected(object):\n",
    "    \"\"\"Fully connected layer 'y = Wx + b'.\n",
    "\n",
    "    Arguments:\n",
    "        shape (tuple): the shape of the fully connected layer. shape[0] is the\n",
    "            output size and shape[1] is the input size.\n",
    "        weights_init (obj):  an object instantiated using any initializer class\n",
    "                in the \"initializer\" module.\n",
    "        bias_init (obj):  an object instantiated using any initializer class\n",
    "                in the \"initializer\" module.\n",
    "        name (str): the name of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        W (np.array): the weights of the fully connected layer.\n",
    "        b (np.array): the biases of the fully connected layer.\n",
    "        shape (tuple): the shape of the fully connected layer. shape[0] is the\n",
    "            output size and shape[1] is the input size.\n",
    "        name (str): the name of the layer.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, d_in, d_out, weights_init=None, bias_init=None, name=\"FullyConnected\"\n",
    "    ):\n",
    "        shape = (d_out, d_in)\n",
    "        self.W = weights_init.initialize(shape) \\\n",
    "            if weights_init else np.random.randn(*shape).astype(np.float32)\n",
    "        self.b = bias_init.initialize((shape[0])) \\\n",
    "            if bias_init else np.random.randn(shape[0]).astype(np.float32)\n",
    "        self.shape = shape\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}({}, {})\".format(self.name, self.shape[0], self.shape[1])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Compute the layer output.\n",
    "\n",
    "        Args:\n",
    "            x (np.array): the input of the layer.\n",
    "\n",
    "        Returns:\n",
    "            The output of the layer.\n",
    "\n",
    "        \"\"\"\n",
    "        Y = np.dot(self.W, x) + self.b\n",
    "        return Y\n",
    "\n",
    "    def backward(self, x, dv_y):\n",
    "        \"\"\"Compute the gradients of weights and biases and the gradient with\n",
    "        respect to the input.\n",
    "\n",
    "        Args:\n",
    "            x (np.array): the input of the layer.\n",
    "            dv_y (np.array): The derivative of the loss with respect to the\n",
    "                output.\n",
    "\n",
    "        Returns:\n",
    "            dv_x (np.array): The derivative of the loss with respect to the\n",
    "                input.\n",
    "            dv_W (np.array): The derivative of the loss with respect to the\n",
    "                weights.\n",
    "            dv_b (np.array): The derivative of the loss with respect to the\n",
    "                biases.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: write your implementation below\n",
    "        dv_x = np.empty(x.shape, dtype=np.float32)\n",
    "        dv_W = np.empty(self.W.shape, dtype=np.float32)\n",
    "        dv_b = np.empty(self.b.shape, dtype=np.float32)\n",
    "\n",
    "        # don't change the order of return values\n",
    "        dv_b = dv_y\n",
    "        dv_W = np.outer(dv_y.T, x)\n",
    "        dv_x = np.dot(self.W.T, dv_y)\n",
    "        \n",
    "        return dv_x, dv_W, dv_b\n",
    "\n",
    "class Conv2D(object):\n",
    "    \"\"\"2D convolutional layer.\n",
    "\n",
    "    Arguments:\n",
    "        filter_size (tuple): the shape of the filter. It is a tuple = (\n",
    "            out_channels, in_channels, filter_height, filter_width).\n",
    "        strides (int or tuple): the strides of the convolution operation.\n",
    "            padding (int or tuple): number of zero paddings.\n",
    "        weights_init (obj):  an object instantiated using any initializer class\n",
    "                in the \"initializer\" module.\n",
    "        bias_init (obj):  an object instantiated using any initializer class\n",
    "                in the \"initializer\" module.\n",
    "        name (str): the name of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        W (np.array): the weights of the layer. A 4D array of shape (\n",
    "            out_channels, in_channels, filter_height, filter_width).\n",
    "        b (np.array): the biases of the layer. A 1D array of shape (\n",
    "            in_channels).\n",
    "        filter_size (tuple): the shape of the filter. It is a tuple = (\n",
    "            out_channels, in_channels, filter_height, filter_width).\n",
    "        strides (tuple): the strides of the convolution operation. A tuple = (\n",
    "            height_stride, width_stride).\n",
    "        padding (tuple): the number of zero paddings along the height and\n",
    "            width. A tuple = (height_padding, width_padding).\n",
    "        name (str): the name of the layer.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, in_channel, out_channel, kernel_size, stride, padding,\n",
    "            weights_init=None, bias_init=None, name=\"Conv2D\"):\n",
    "        filter_size = (out_channel, in_channel, *kernel_size)\n",
    "\n",
    "        self.W = weights_init.initialize(filter_size) \\\n",
    "            if weights_init else np.random.randn(*filter_size).astype(np.float32)\n",
    "        self.b = bias_init.initialize((filter_size[0], 1)) \\\n",
    "            if bias_init else np.random.randn(out_channel, 1).astype(np.float32)\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = (stride, stride) if type(stride) == int else stride\n",
    "        self.padding = (padding, padding) if type(padding) == int else padding\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}({}, {}, {})\".format(\n",
    "            self.name, self.kernel_size, self.stride, self.padding\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Compute the layer output.\n",
    "\n",
    "        Args:\n",
    "            x (np.array): the input of the layer. A 3D array of shape (\n",
    "                in_channels, in_heights, in_weights).\n",
    "\n",
    "        Returns:\n",
    "            The output of the layer. A 3D array of shape (out_channels,\n",
    "                out_heights, out_weights).\n",
    "\n",
    "        \"\"\"\n",
    "        p, s = self.padding, self.stride\n",
    "        x_padded = np.pad(\n",
    "            x, ((0, 0), (p[0], p[0]), (p[1], p[1])), mode='constant'\n",
    "        )\n",
    "\n",
    "        # check dimensions\n",
    "        assert (x.shape[1] - self.W.shape[2] + 2 * p[0]) / s[0] + 1 > 0, \\\n",
    "                'Height doesn\\'t work'\n",
    "        assert (x.shape[2] - self.W.shape[3] + 2 * p[1]) / s[1] + 1 > 0, \\\n",
    "                'Width doesn\\'t work'\n",
    "\n",
    "        y_shape = (\n",
    "            self.W.shape[0],\n",
    "            int((x.shape[1] - self.W.shape[2] + 2 * p[0]) / s[0]) + 1,\n",
    "            int((x.shape[2] - self.W.shape[3] + 2 * p[1]) / s[1]) + 1,\n",
    "        )\n",
    "        y = np.empty(y_shape, dtype=np.float32)\n",
    "\n",
    "        for k in range(y.shape[0]):\n",
    "            for i in range(y.shape[1]):\n",
    "                for j in range(y.shape[2]):\n",
    "                    y[k, i, j] = np.sum(\n",
    "                        x_padded[\n",
    "                            :,\n",
    "                            i * s[0] : i * s[0] + self.W.shape[2],\n",
    "                            j * s[1] : j * s[1] + self.W.shape[3]\n",
    "                        ] * self.W[k]\n",
    "                    ) + self.b[k]\n",
    "        return y\n",
    "\n",
    "    def backward(self, x, dv_y):\n",
    "        \"\"\"Compute the gradients of weights and biases and the gradient with\n",
    "        respect to the input.\n",
    "\n",
    "        Args:\n",
    "            x (np.array): the input of the layer. A 3D array of shape (\n",
    "                in_channels, in_heights, in_weights).\n",
    "            dv_y (np.array): The derivative of the loss with respect to the\n",
    "                output. A 3D array of shape (out_channels, out_heights,\n",
    "                out_weights).\n",
    "\n",
    "        Returns:\n",
    "            dv_x (np.array): The derivative of the loss with respect to the\n",
    "                input. It has the same shape as x.\n",
    "            dv_W (np.array): The derivative of the loss with respect to the\n",
    "                weights. It has the same shape as self.W\n",
    "            dv_b (np.array): The derivative of the loss with respect to the\n",
    "                biases. It has the same shape as self.b\n",
    "\n",
    "        \"\"\"\n",
    "        p, s = self.padding, self.stride\n",
    "        x_padded = np.pad(\n",
    "            x, ((0, 0), (p[0], p[0]), (p[1], p[1])), mode='constant'\n",
    "        )\n",
    "\n",
    "        # TODO: write your implementation below\n",
    "\n",
    "        dv_W = np.zeros(self.W.shape, dtype=np.float64)\n",
    "        dv_b = np.zeros(self.b.shape, dtype=np.float64)\n",
    "        dv_x = np.zeros(x.shape, dtype=np.float64)\n",
    "        \n",
    "            ###dv_b###\n",
    "        for i in range(dv_y.shape[0]):\n",
    "            \n",
    "            dv_b[i] = np.sum(dv_y[i])\n",
    "            ###dv_b###\n",
    "            \n",
    "            ###dv_W###\n",
    "        for k in range(dv_W.shape[0]):\n",
    "            \n",
    "            for t in range(x.shape[0]):\n",
    "                \n",
    "                for i in range(dv_y.shape[1]):\n",
    "                    for j in range(dv_y.shape[2]):                       \n",
    "                \n",
    "                        for m in range(self.W.shape[2]):\n",
    "                            for n in range(self.W.shape[3]):\n",
    "                                \n",
    "                                dv_W[k][t][m][n] += np.multiply(x[t][s[0] * m + i][s[1] * n + j], dv_y[k][i][j])\n",
    "            ###dv_W###\n",
    "            \n",
    "            ###dv_X###\n",
    "        #dv_y_padded = np.pad(dv_y, ((0, 0), (self.W.shape[2] - 1, self.W.shape[2] - 1), (self.W.shape[3] - 1, self.W.shape[3] - 1)), mode='constant')\n",
    "\n",
    "        for k in range(self.W.shape[0]):\n",
    "            \n",
    "            for t in range(self.W.shape[1]):\n",
    "                \n",
    "                for i in range(dv_y.shape[1]):\n",
    "                    for j in range(dv_y.shape[2]):\n",
    "                \n",
    "                        for m in range(self.W.shape[2]):\n",
    "                            for n in range(self.W.shape[3]):\n",
    "                                \n",
    "                                dv_x[t][i + m][j + n] += self.W[k][t][m][n] * dv_y[k][i][j]\n",
    "                                \n",
    "                                #dv_x[t][i][j] += self.W[k][t][-(m + 1)][-(n + 1)] * dv_y_padded[k][i//s[0] + m][j//s[1] + n]\n",
    "            ###dv_X###\n",
    "                        \n",
    "\n",
    "        # don't change the order of return values\n",
    "        return dv_x, dv_W, dv_b\n",
    "\n",
    "class MaxPool2D:\n",
    "    def __init__(self, kernel_size, stride, padding, name=\"MaxPool2D\"):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = (stride, stride) if type(stride) == int else stride\n",
    "        self.padding = (padding, padding) if type(padding) == int else padding\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}({}, {}, {})\".format(\n",
    "            self.name, self.kernel_size, self.stride, self.padding\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Compute the layer output.\n",
    "\n",
    "        Arguments:\n",
    "            x {[np.array]} -- the input of the layer. A 3D array of shape (\n",
    "                              in_channels, in_heights, in_weights).\n",
    "        Returns:\n",
    "            The output of the layer. A 3D array of shape (out_channels,\n",
    "                out_heights, out_weights).\n",
    "        \"\"\"\n",
    "        p, s = self.padding, self.stride\n",
    "        x_padded = np.pad(\n",
    "            x, ((0, 0), (p[0], p[0]), (p[1], p[1])), mode='constant'\n",
    "        )\n",
    "\n",
    "        # check dimensions\n",
    "        assert (x.shape[1] - self.kernel_size[0] + 2 * p[0]) / s[0] + 1 > 0, \\\n",
    "            'Height doesn\\'t work'\n",
    "        assert (x.shape[2] - self.kernel_size[1] + 2 * p[1]) / s[1] + 1 > 0, \\\n",
    "            'Width doesn\\'t work'\n",
    "\n",
    "        y_shape = (\n",
    "            x.shape[0],\n",
    "            int((x.shape[1] - self.kernel_size[0] + 2 * p[0]) / s[0]) + 1,\n",
    "            int((x.shape[2] - self.kernel_size[1] + 2 * p[1]) / s[1]) + 1,\n",
    "        )\n",
    "        y = np.empty(y_shape, dtype=np.float32)\n",
    "\n",
    "        for i in range(y.shape[1]):\n",
    "            for j in range(y.shape[2]):\n",
    "                y[:, i, j] = np.max(x_padded[\n",
    "                                    :,\n",
    "                                    i * s[0]: i * s[0] + self.kernel_size[0],\n",
    "                                    j * s[1]: j * s[1] + self.kernel_size[1]\n",
    "                                    ].reshape(-1, self.kernel_size[0] * self.kernel_size[1]),\n",
    "                                    axis=1\n",
    "                                    )\n",
    "\n",
    "        return y\n",
    "\n",
    "    def backward(self, x, dv_y):\n",
    "        \"\"\"Compute the gradients of weights and biases and the gradient with\n",
    "                respect to the input.\n",
    "\n",
    "                Args:\n",
    "                    x (np.array): the input of the layer. A 3D array of shape (\n",
    "                        in_channels, in_heights, in_weights).\n",
    "                    dv_y (np.array): The derivative of the loss with respect to the\n",
    "                        output. A 3D array of shape (out_channels, out_heights,\n",
    "                        out_weights).\n",
    "\n",
    "                Returns:\n",
    "                    dv_x (np.array): The derivative of the loss with respect to the\n",
    "                        input. It has the same shape as x.\n",
    "                \"\"\"\n",
    "        p, s = self.padding, self.stride\n",
    "        x_padded = np.pad(\n",
    "            x, ((0, 0), (p[0], p[0]), (p[1], p[1])), mode='constant'\n",
    "        )\n",
    "\n",
    "        # TODO: write your implementation below\n",
    "        #dv_x = np.empty(x.shape, dtype=np.float32)\n",
    "        dv_x = np.zeros(x.shape, dtype=np.float64)\n",
    "        \n",
    "        for t in range(x.shape[0]):\n",
    "            \n",
    "            for i in range(dv_y.shape[1]):\n",
    "                for j in range(dv_y.shape[2]):\n",
    "                    \n",
    "                    current_max = -999_999_999\n",
    "                    coords = [None, None]\n",
    "                    \n",
    "                    for m in range(self.kernel_size[0]):\n",
    "                        for n in range(self.kernel_size[1]):\n",
    "                            \n",
    "                            if current_max < x_padded[t][i * s[0] + m][j * s[1] + n]:\n",
    "                                current_max = x_padded[t][i * s[0] + m][j * s[1] + n]\n",
    "                                coords[0] = m + i * s[0]\n",
    "                                coords[1] = n + j * s[1]\n",
    "                    \n",
    "                    dv_x[t][coords[0]][coords[1]] += dv_y[t][i][j]\n",
    "                    \n",
    "        return dv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "\n",
      "\n",
      "\n",
      "True\n",
      "True\n",
      "True\n",
      "\n",
      "\n",
      "\n",
      "True\n",
      "True\n",
      "True\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for case in conv_cases:\n",
    "    weight = case['weight']\n",
    "    out_c, in_c, h, w = weight.shape\n",
    "    bias = case['bias']\n",
    "    x = case['x']\n",
    "    out = case['out']\n",
    "    stride = case['stride']\n",
    "    pad = case['pad']\n",
    "    grad_output = case['grad_output']\n",
    "    grad_x = case['grad_x']\n",
    "    grad_w = case['grad_w']\n",
    "    grad_b = case['grad_b']\n",
    "\n",
    "    conv = Conv2D(in_channel=in_c,\n",
    "                  out_channel=out_c,\n",
    "                  kernel_size=(h, w),\n",
    "                  stride=stride,\n",
    "                  padding=pad)\n",
    "    conv.W = weight\n",
    "    conv.b = bias\n",
    "    test_out = conv(x)\n",
    "    dv_x, dv_W, dv_b = conv.backward(x, grad_output)\n",
    "    \n",
    "    print(np.allclose(grad_x, dv_x, rtol=0.0001))\n",
    "    print(np.allclose(grad_w, dv_W, rtol=0.0001))\n",
    "    print(np.allclose(grad_b, dv_b, rtol=0.0001))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.15467713e-01 -2.55054446e-01 -1.88274135e-01  1.77041068e-01\n",
      "    1.09686033e+00  5.64804397e-01  4.01296492e-01  4.64555789e-01\n",
      "    2.75689773e-01  4.22841851e-02  2.94088820e-01 -4.49973862e-01\n",
      "    1.82049539e-01  5.32507584e-01  3.60694276e-01  3.10940458e-02\n",
      "   -1.66649012e-01  5.02818815e-01  8.73779701e-02  6.77837385e-02\n",
      "   -3.16725380e-01 -3.23223080e-01 -2.99189419e-01]\n",
      "  [-3.34615381e-01  6.21533096e-02  6.43994516e-01 -7.49668491e-01\n",
      "   -3.41789896e-01 -4.12406493e-01 -4.94804570e-01 -3.22321763e-02\n",
      "   -6.93489696e-02  2.37267772e-01 -9.65248972e-01  1.27701937e+00\n",
      "   -1.01153437e+00  5.64872457e-01 -8.01300549e-01  3.10140738e-01\n",
      "    3.84574319e-01  7.54025076e-01 -1.13202819e+00 -1.07711572e+00\n",
      "   -3.72776708e-01  8.16722354e-01  3.87704644e-01]\n",
      "  [-1.55423583e-01 -8.75054419e-01  2.37540173e-01  8.01017160e-01\n",
      "    6.52695438e-01 -6.99188388e-01 -8.84186700e-01 -7.93934746e-01\n",
      "    8.48170402e-01 -2.91464847e-01 -9.94580250e-01  5.11115480e-01\n",
      "    2.05940167e-01  1.47634606e-02  9.91888900e-01 -1.51552123e+00\n",
      "   -8.56830704e-01  2.54885815e-01  1.09019673e+00 -1.13069037e+00\n",
      "    1.99954096e-01  4.63162972e-01  5.38875211e-01]\n",
      "  [-1.11857549e-02  1.37544071e-01  9.47628392e-01 -2.09224069e-01\n",
      "    1.31068437e+00  9.10704868e-01 -3.30470404e-01 -4.61232260e-01\n",
      "    6.20813136e-01  5.23735389e-01  6.09571760e-01  8.62311078e-01\n",
      "    6.07379942e-01 -2.27612190e+00  6.49016211e-02  6.25058730e-01\n",
      "    2.55184310e-01 -1.74416479e+00 -1.00755509e+00  1.33981458e-01\n",
      "    1.10650848e+00  4.22027575e-01 -2.50483230e-01]\n",
      "  [ 3.23753036e-01 -1.30281475e+00  1.61297554e+00  1.45916035e+00\n",
      "   -1.98255142e+00  1.90639868e+00 -5.54389185e-01  3.70819126e-01\n",
      "   -2.72047310e-01  1.28954123e-01  3.17852799e-01 -1.09406229e+00\n",
      "   -8.50276824e-01 -4.36851820e-01 -1.84007839e+00 -3.17085948e-01\n",
      "   -4.64882008e-01 -6.25109839e-01  2.31340054e-01 -6.18599228e-01\n",
      "   -4.09317462e-01  1.38769312e+00  5.52404428e-01]\n",
      "  [ 1.09985039e-01  4.82902527e-01 -7.23980732e-01  1.42550584e+00\n",
      "    1.12469872e+00  5.20545099e-01  3.09509347e-02 -9.69307089e-01\n",
      "    7.10245250e-01 -1.15085931e+00 -9.01867976e-01  6.29845337e-01\n",
      "   -3.91798263e-01  1.41005537e-01  1.30809983e-01 -8.50451074e-01\n",
      "   -2.21961154e-01  1.28593794e+00 -2.11282620e+00  1.92058313e+00\n",
      "   -9.86262159e-01  1.29055559e+00  2.08312101e-01]\n",
      "  [-3.17136468e-02 -5.09891296e-01 -6.72276292e-01 -1.23079884e+00\n",
      "    7.88296896e-01  1.25725274e+00 -3.06286627e-01 -9.78140569e-01\n",
      "   -1.88930207e-01 -2.00750192e-01  3.98397884e-01  1.04574009e-01\n",
      "    1.10354007e+00 -3.23967018e-01 -6.55390350e-02  1.75592449e+00\n",
      "   -9.49251261e-01 -7.38360733e-01  2.36999825e-01  1.18477342e+00\n",
      "    5.15860642e-01 -8.87049070e-01  7.33439764e-02]\n",
      "  [-5.03746512e-01 -1.88136398e+00  2.70885019e-01  7.70319637e-02\n",
      "   -9.22032781e-01  5.02741176e-01  1.42805920e+00  5.79422831e-01\n",
      "    4.22179463e-01  1.84319543e-01 -5.83689888e-02  2.06244885e-01\n",
      "    7.58454980e-01  5.70523431e-01 -1.12082746e+00 -1.06605499e-02\n",
      "    1.73462475e+00  5.23174820e-02 -5.52025343e-01 -1.24649263e+00\n",
      "    5.45221691e-01  1.03437949e+00  5.83823480e-01]\n",
      "  [-5.54774134e-01 -8.99842531e-01 -1.28936675e+00  1.09922714e+00\n",
      "   -3.60242841e-01  9.17838677e-01  5.06364016e-02 -1.42362275e+00\n",
      "    5.63490954e-02  3.74082081e-01 -4.57514069e-01 -6.34298434e-01\n",
      "    1.76497490e+00  7.72036942e-01  5.58338554e-01  6.30879514e-02\n",
      "    1.04979982e+00  2.16171939e+00 -8.15200133e-01  1.91991256e-01\n",
      "   -1.05744471e+00  4.38124687e-01  3.22291049e-01]\n",
      "  [ 1.62984945e-01  3.81146111e-01 -3.66368159e-01  1.28085216e+00\n",
      "    4.52218665e-01 -8.56245747e-01  1.08815542e-01  2.31673735e-01\n",
      "    4.81582939e-01 -4.91353429e-01  5.13392256e-01  1.18746576e+00\n",
      "    1.09027887e+00  2.34637913e-01  7.47045382e-01  3.44834825e-01\n",
      "   -3.48064711e-01  7.84820653e-01  1.08392744e+00 -9.95210028e-01\n",
      "   -8.64292559e-01 -1.91115731e-01  4.06634118e-01]\n",
      "  [ 1.81069350e-01  6.74990908e-01  1.27153157e+00  5.15619517e-01\n",
      "    6.32652022e-01  1.02869833e+00 -1.31547272e+00 -6.42954027e-01\n",
      "    7.46367305e-01  7.52807991e-02 -1.75449373e+00 -1.29567971e-02\n",
      "    1.23235717e+00  7.47483285e-01 -1.94048690e-01 -1.02637328e+00\n",
      "    9.84095344e-01 -4.76140844e-01  2.19269290e-01  9.98124551e-01\n",
      "    9.42833393e-01  9.00048998e-01  1.75873047e-01]\n",
      "  [ 3.10819169e-01 -9.29526860e-01  4.07199241e-01  3.21071412e-01\n",
      "    2.79788866e-01 -9.76467423e-01  1.07559271e-01 -1.28527395e+00\n",
      "   -9.36114766e-01  1.33166772e+00  1.18816861e+00 -1.60767102e+00\n",
      "   -5.43273451e-01 -1.20290281e-01  1.35909807e+00 -4.34989189e-01\n",
      "    4.71988732e-01  8.58765193e-01  5.26487376e-01  5.86105851e-01\n",
      "   -3.45240891e-01 -1.41617062e+00 -7.42884011e-01]\n",
      "  [-3.50921427e-01  4.42891382e-01  7.55558517e-01 -2.51199280e-01\n",
      "    1.67984480e-01  1.19318628e+00 -8.52332436e-01  7.30004059e-01\n",
      "    5.59602049e-01  4.21829882e-01  6.64286419e-03  9.15398293e-02\n",
      "    1.52808721e-01  6.03919514e-01 -2.37463093e-01  3.85253052e-01\n",
      "   -1.07410118e+00  2.13819816e+00 -2.62270429e-02  3.81850693e-02\n",
      "   -1.32759796e+00  1.13803881e+00 -4.70977178e-01]\n",
      "  [ 1.33211819e-01 -1.22085116e+00  9.22248657e-02 -9.07429266e-01\n",
      "   -5.94197209e-01 -4.01857451e-01 -7.03391323e-02  1.20853618e-01\n",
      "    2.79177667e-01  6.09510010e-01 -9.57014689e-01 -9.53673098e-01\n",
      "   -6.64133579e-01 -6.82263285e-02  1.76673606e+00 -7.05468672e-01\n",
      "    1.59349206e+00  7.07704307e-01  6.21804864e-01  1.78844973e+00\n",
      "   -9.52864368e-01 -1.48564703e+00 -1.02405725e+00]\n",
      "  [ 4.20968831e-01  4.36081279e-01 -4.97276646e-01  9.82539099e-01\n",
      "    3.22339001e-01  3.42583437e-01 -2.33956176e-01  6.84056321e-01\n",
      "    1.76902158e+00 -1.09960597e+00  1.37300476e+00 -1.54813913e+00\n",
      "    3.46753150e-01 -7.85402659e-01 -4.64686832e-01  1.03865084e+00\n",
      "   -1.98511871e-01 -1.53292488e-01 -1.73839831e+00 -5.86683950e-01\n",
      "    2.09687504e+00  4.75356134e-01 -5.04208615e-01]\n",
      "  [-1.37580968e-01  5.21687191e-01  6.70347580e-01  9.50352831e-01\n",
      "    8.43713173e-01  7.12524321e-01  3.11911311e-01 -5.13037241e-01\n",
      "    4.35641944e-01 -7.72159015e-01  4.89842861e-01 -5.21078794e-01\n",
      "    6.59452635e-01  1.84633388e+00 -1.34295531e-01 -1.28503998e+00\n",
      "    9.59231798e-01 -7.03138309e-02 -1.83617216e+00 -6.69663174e-01\n",
      "   -1.42743153e-01 -9.48250501e-01 -1.52016492e-01]\n",
      "  [ 9.57065821e-01 -9.92567553e-01 -9.64223270e-02  7.98884827e-01\n",
      "    9.72381099e-01 -1.25803044e+00  1.81261202e-01  1.21277827e-01\n",
      "    9.80820834e-01 -3.94660834e-01 -1.58737518e-01  2.59430676e-01\n",
      "   -1.75857690e+00  6.38250415e-01 -1.17046598e+00  6.22960546e-01\n",
      "   -3.15401650e-01  8.73751649e-01 -3.64598325e-01 -6.58681670e-01\n",
      "   -8.76253203e-01  1.45104668e+00  4.76438866e-01]\n",
      "  [-4.45907210e-01  5.66184608e-01 -1.65106067e-01 -7.83085202e-01\n",
      "    9.36130800e-01 -1.31022257e+00 -8.81698798e-01 -6.65622538e-01\n",
      "    1.11364954e+00 -8.63759941e-01  1.04943522e+00 -1.33723452e+00\n",
      "   -8.09649237e-01 -7.84182320e-01 -2.63370662e-01 -8.33480728e-01\n",
      "   -9.43384035e-01 -1.77449741e+00  4.06575304e-01  1.92825194e-03\n",
      "   -1.88097569e-01  5.46042554e-02  3.15602756e-01]\n",
      "  [ 5.09179958e-01 -1.09449760e+00  3.08629586e-02  1.11159629e+00\n",
      "   -1.77721485e+00 -2.23074405e-02 -6.79267298e-01  1.07303536e+00\n",
      "   -2.25549897e-01  1.00508876e+00 -9.02185255e-01 -4.75444544e-01\n",
      "   -4.70256974e-01 -2.03616147e+00 -1.43873201e+00 -1.21529951e-01\n",
      "    2.61840351e-01  3.36308249e-01 -1.15067908e+00 -2.07256919e-01\n",
      "   -7.77491813e-01  1.59816008e+00  4.57945960e-01]\n",
      "  [-2.44052521e-01  5.91772260e-01 -1.10278855e-01 -6.63630046e-01\n",
      "    1.64620644e+00  3.61600956e-01 -7.04807811e-01 -8.59563946e-02\n",
      "   -1.15242728e+00  9.83998264e-01  1.03082462e+00 -3.07376287e-01\n",
      "   -1.84266432e-02  1.43328040e-01 -9.67393230e-02  1.51392596e+00\n",
      "   -1.42558769e+00  1.11262863e+00  3.81792276e-01  1.74298043e+00\n",
      "    2.28183524e+00 -3.02570556e-01 -7.38143502e-02]\n",
      "  [ 5.97184324e-02  2.53263032e-01  2.82629073e+00 -1.42345853e+00\n",
      "    1.03489467e+00  1.95643127e-01 -2.37888975e-01  7.67470374e-01\n",
      "    5.19999117e-03 -7.21285539e-01 -9.46215987e-02 -3.20452960e-01\n",
      "   -2.65719492e-01 -7.24503566e-01 -1.09485025e+00 -1.68282444e+00\n",
      "   -2.34554209e-01  4.02769321e-01 -3.06876203e-01 -1.48827995e+00\n",
      "    4.96789230e-01  2.05113521e-02  5.91304926e-02]\n",
      "  [-5.62501751e-01 -5.55974264e-02 -8.81470516e-02  4.07052985e-01\n",
      "    2.97979378e-01 -2.54812215e-01 -1.08870382e+00 -4.56115091e-02\n",
      "    1.16504865e+00 -7.22367761e-02 -5.22914993e-01  3.82854596e-01\n",
      "    3.31940836e-01  6.40683291e-01 -4.28140860e-02 -7.09821457e-01\n",
      "    4.95783058e-01  8.52950108e-01  1.12193972e+00  2.17484724e-01\n",
      "    5.79635175e-01  7.41665277e-01  6.33399448e-01]\n",
      "  [ 1.83508627e-01 -3.29243129e-01  6.56942860e-02  9.75765898e-01\n",
      "    3.01737599e-01 -3.06836029e-01  6.64309880e-01 -5.54675968e-01\n",
      "    1.65321674e-01 -7.71360472e-02 -3.45827453e-01  6.97497278e-01\n",
      "   -1.04036145e-02 -3.47737946e-01 -1.22311496e-01 -6.72395164e-01\n",
      "    4.66488034e-01  9.36531862e-02 -1.25685966e+00  4.75568032e-01\n",
      "   -8.32659770e-02 -4.55625281e-01 -2.75531071e-02]]]\n"
     ]
    }
   ],
   "source": [
    "print(dv_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.15467712e-01 -2.55054444e-01 -1.88274115e-01  1.77041069e-01\n",
      "    1.09686041e+00  5.64804435e-01  4.01296496e-01  4.64555770e-01\n",
      "    2.75689781e-01  4.22841758e-02  2.94088811e-01 -4.49973911e-01\n",
      "    1.82049513e-01  5.32507598e-01  3.60694289e-01  3.10940426e-02\n",
      "   -1.66649014e-01  5.02818823e-01  8.73779356e-02  6.77837431e-02\n",
      "   -3.16725373e-01 -3.23223084e-01 -2.99189419e-01]\n",
      "  [-3.34615380e-01  6.21533394e-02  6.43994510e-01 -7.49668598e-01\n",
      "   -3.41789961e-01 -4.12406504e-01 -4.94804591e-01 -3.22321877e-02\n",
      "   -6.93489835e-02  2.37267733e-01 -9.65248942e-01  1.27701938e+00\n",
      "   -1.01153433e+00  5.64872503e-01 -8.01300526e-01  3.10140729e-01\n",
      "    3.84574294e-01  7.54025042e-01 -1.13202834e+00 -1.07711577e+00\n",
      "   -3.72776657e-01  8.16722393e-01  3.87704641e-01]\n",
      "  [-1.55423582e-01 -8.75054419e-01  2.37540230e-01  8.01017106e-01\n",
      "    6.52695417e-01 -6.99188471e-01 -8.84186745e-01 -7.93934703e-01\n",
      "    8.48170400e-01 -2.91464806e-01 -9.94580269e-01  5.11115432e-01\n",
      "    2.05940202e-01  1.47634447e-02  9.91888881e-01 -1.51552129e+00\n",
      "   -8.56830597e-01  2.54885793e-01  1.09019685e+00 -1.13069034e+00\n",
      "    1.99954137e-01  4.63162959e-01  5.38875163e-01]\n",
      "  [-1.11857653e-02  1.37544066e-01  9.47628379e-01 -2.09224105e-01\n",
      "    1.31068420e+00  9.10704911e-01 -3.30470324e-01 -4.61232334e-01\n",
      "    6.20813131e-01  5.23735404e-01  6.09571755e-01  8.62311125e-01\n",
      "    6.07379913e-01 -2.27612185e+00  6.49016351e-02  6.25058770e-01\n",
      "    2.55184323e-01 -1.74416471e+00 -1.00755513e+00  1.33981496e-01\n",
      "    1.10650849e+00  4.22027588e-01 -2.50483245e-01]\n",
      "  [ 3.23753029e-01 -1.30281472e+00  1.61297572e+00  1.45916033e+00\n",
      "   -1.98255146e+00  1.90639853e+00 -5.54389179e-01  3.70819271e-01\n",
      "   -2.72047400e-01  1.28954083e-01  3.17852855e-01 -1.09406221e+00\n",
      "   -8.50276828e-01 -4.36851859e-01 -1.84007835e+00 -3.17085922e-01\n",
      "   -4.64882046e-01 -6.25109792e-01  2.31340051e-01 -6.18599236e-01\n",
      "   -4.09317464e-01  1.38769305e+00  5.52404404e-01]\n",
      "  [ 1.09985046e-01  4.82902527e-01 -7.23980784e-01  1.42550588e+00\n",
      "    1.12469888e+00  5.20545125e-01  3.09508890e-02 -9.69307125e-01\n",
      "    7.10245192e-01 -1.15085924e+00 -9.01867926e-01  6.29845262e-01\n",
      "   -3.91798288e-01  1.41005576e-01  1.30810007e-01 -8.50451052e-01\n",
      "   -2.21961111e-01  1.28593802e+00 -2.11282611e+00  1.92058301e+00\n",
      "   -9.86262143e-01  1.29055548e+00  2.08312109e-01]\n",
      "  [-3.17136496e-02 -5.09891272e-01 -6.72276378e-01 -1.23079884e+00\n",
      "    7.88296878e-01  1.25725281e+00 -3.06286573e-01 -9.78140593e-01\n",
      "   -1.88930184e-01 -2.00750172e-01  3.98397863e-01  1.04573995e-01\n",
      "    1.10354006e+00 -3.23967010e-01 -6.55390769e-02  1.75592434e+00\n",
      "   -9.49251294e-01 -7.38360703e-01  2.36999869e-01  1.18477345e+00\n",
      "    5.15860558e-01 -8.87049079e-01  7.33439624e-02]\n",
      "  [-5.03746510e-01 -1.88136399e+00  2.70885110e-01  7.70319700e-02\n",
      "   -9.22032833e-01  5.02741218e-01  1.42805910e+00  5.79422832e-01\n",
      "    4.22179490e-01  1.84319526e-01 -5.83689958e-02  2.06244797e-01\n",
      "    7.58454978e-01  5.70523441e-01 -1.12082744e+00 -1.06605291e-02\n",
      "    1.73462474e+00  5.23174703e-02 -5.52025318e-01 -1.24649262e+00\n",
      "    5.45221686e-01  1.03437948e+00  5.83823442e-01]\n",
      "  [-5.54774165e-01 -8.99842501e-01 -1.28936672e+00  1.09922719e+00\n",
      "   -3.60242844e-01  9.17838693e-01  5.06364256e-02 -1.42362273e+00\n",
      "    5.63490987e-02  3.74082059e-01 -4.57514048e-01 -6.34298384e-01\n",
      "    1.76497495e+00  7.72036910e-01  5.58338642e-01  6.30879626e-02\n",
      "    1.04979992e+00  2.16171932e+00 -8.15200090e-01  1.91991284e-01\n",
      "   -1.05744469e+00  4.38124716e-01  3.22291046e-01]\n",
      "  [ 1.62984937e-01  3.81146133e-01 -3.66368115e-01  1.28085208e+00\n",
      "    4.52218711e-01 -8.56245816e-01  1.08815551e-01  2.31673732e-01\n",
      "    4.81582969e-01 -4.91353482e-01  5.13392210e-01  1.18746591e+00\n",
      "    1.09027886e+00  2.34637976e-01  7.47045398e-01  3.44834775e-01\n",
      "   -3.48064750e-01  7.84820616e-01  1.08392751e+00 -9.95209992e-01\n",
      "   -8.64292562e-01 -1.91115752e-01  4.06634092e-01]\n",
      "  [ 1.81069359e-01  6.74990952e-01  1.27153158e+00  5.15619516e-01\n",
      "    6.32652044e-01  1.02869833e+00 -1.31547284e+00 -6.42953992e-01\n",
      "    7.46367276e-01  7.52807558e-02 -1.75449383e+00 -1.29567981e-02\n",
      "    1.23235726e+00  7.47483253e-01 -1.94048643e-01 -1.02637339e+00\n",
      "    9.84095335e-01 -4.76140887e-01  2.19269365e-01  9.98124540e-01\n",
      "    9.42833304e-01  9.00048971e-01  1.75873056e-01]\n",
      "  [ 3.10819149e-01 -9.29526746e-01  4.07199204e-01  3.21071416e-01\n",
      "    2.79788882e-01 -9.76467490e-01  1.07559256e-01 -1.28527391e+00\n",
      "   -9.36114788e-01  1.33166766e+00  1.18816853e+00 -1.60767102e+00\n",
      "   -5.43273509e-01 -1.20290309e-01  1.35909808e+00 -4.34989184e-01\n",
      "    4.71988767e-01  8.58765125e-01  5.26487470e-01  5.86105824e-01\n",
      "   -3.45240831e-01 -1.41617060e+00 -7.42884040e-01]\n",
      "  [-3.50921452e-01  4.42891419e-01  7.55558550e-01 -2.51199305e-01\n",
      "    1.67984456e-01  1.19318628e+00 -8.52332473e-01  7.30004072e-01\n",
      "    5.59602141e-01  4.21829879e-01  6.64285570e-03  9.15398896e-02\n",
      "    1.52808696e-01  6.03919506e-01 -2.37463087e-01  3.85253072e-01\n",
      "   -1.07410109e+00  2.13819814e+00 -2.62270123e-02  3.81851196e-02\n",
      "   -1.32759786e+00  1.13803875e+00 -4.70977187e-01]\n",
      "  [ 1.33211821e-01 -1.22085118e+00  9.22248363e-02 -9.07429278e-01\n",
      "   -5.94197273e-01 -4.01857406e-01 -7.03391731e-02  1.20853640e-01\n",
      "    2.79177666e-01  6.09510005e-01 -9.57014680e-01 -9.53673065e-01\n",
      "   -6.64133549e-01 -6.82263225e-02  1.76673603e+00 -7.05468714e-01\n",
      "    1.59349215e+00  7.07704425e-01  6.21804893e-01  1.78844988e+00\n",
      "   -9.52864408e-01 -1.48564708e+00 -1.02405727e+00]\n",
      "  [ 4.20968831e-01  4.36081260e-01 -4.97276604e-01  9.82539058e-01\n",
      "    3.22338939e-01  3.42583477e-01 -2.33956188e-01  6.84056282e-01\n",
      "    1.76902151e+00 -1.09960592e+00  1.37300467e+00 -1.54813921e+00\n",
      "    3.46753269e-01 -7.85402656e-01 -4.64686871e-01  1.03865087e+00\n",
      "   -1.98511839e-01 -1.53292492e-01 -1.73839819e+00 -5.86683869e-01\n",
      "    2.09687519e+00  4.75356162e-01 -5.04208624e-01]\n",
      "  [-1.37580991e-01  5.21687150e-01  6.70347452e-01  9.50352728e-01\n",
      "    8.43713164e-01  7.12524295e-01  3.11911285e-01 -5.13037205e-01\n",
      "    4.35641974e-01 -7.72158980e-01  4.89842862e-01 -5.21078825e-01\n",
      "    6.59452677e-01  1.84633398e+00 -1.34295523e-01 -1.28504002e+00\n",
      "    9.59231913e-01 -7.03137964e-02 -1.83617210e+00 -6.69663191e-01\n",
      "   -1.42743260e-01 -9.48250532e-01 -1.52016476e-01]\n",
      "  [ 9.57065821e-01 -9.92567539e-01 -9.64221656e-02  7.98884809e-01\n",
      "    9.72381055e-01 -1.25803041e+00  1.81261167e-01  1.21277809e-01\n",
      "    9.80820775e-01 -3.94660801e-01 -1.58737510e-01  2.59430707e-01\n",
      "   -1.75857687e+00  6.38250411e-01 -1.17046607e+00  6.22960508e-01\n",
      "   -3.15401614e-01  8.73751700e-01 -3.64598393e-01 -6.58681631e-01\n",
      "   -8.76253247e-01  1.45104671e+00  4.76438880e-01]\n",
      "  [-4.45907176e-01  5.66184640e-01 -1.65106043e-01 -7.83085227e-01\n",
      "    9.36130822e-01 -1.31022286e+00 -8.81698728e-01 -6.65622473e-01\n",
      "    1.11364961e+00 -8.63759935e-01  1.04943514e+00 -1.33723450e+00\n",
      "   -8.09649169e-01 -7.84182310e-01 -2.63370693e-01 -8.33480716e-01\n",
      "   -9.43384051e-01 -1.77449751e+00  4.06575322e-01  1.92818046e-03\n",
      "   -1.88097596e-01  5.46042174e-02  3.15602779e-01]\n",
      "  [ 5.09179950e-01 -1.09449756e+00  3.08629274e-02  1.11159635e+00\n",
      "   -1.77721500e+00 -2.23075151e-02 -6.79267287e-01  1.07303536e+00\n",
      "   -2.25549877e-01  1.00508881e+00 -9.02185261e-01 -4.75444466e-01\n",
      "   -4.70256984e-01 -2.03616142e+00 -1.43873215e+00 -1.21529967e-01\n",
      "    2.61840463e-01  3.36308300e-01 -1.15067911e+00 -2.07256824e-01\n",
      "   -7.77491748e-01  1.59816015e+00  4.57945973e-01]\n",
      "  [-2.44052529e-01  5.91772258e-01 -1.10278830e-01 -6.63630068e-01\n",
      "    1.64620638e+00  3.61600995e-01 -7.04807818e-01 -8.59564468e-02\n",
      "   -1.15242732e+00  9.83998299e-01  1.03082466e+00 -3.07376325e-01\n",
      "   -1.84267461e-02  1.43327981e-01 -9.67393219e-02  1.51392591e+00\n",
      "   -1.42558777e+00  1.11262846e+00  3.81792307e-01  1.74298036e+00\n",
      "    2.28183532e+00 -3.02570641e-01 -7.38143325e-02]\n",
      "  [ 5.97184449e-02  2.53263026e-01  2.82629061e+00 -1.42345858e+00\n",
      "    1.03489459e+00  1.95643187e-01 -2.37888932e-01  7.67470360e-01\n",
      "    5.19998372e-03 -7.21285582e-01 -9.46215987e-02 -3.20452929e-01\n",
      "   -2.65719533e-01 -7.24503636e-01 -1.09485030e+00 -1.68282437e+00\n",
      "   -2.34554231e-01  4.02769327e-01 -3.06876153e-01 -1.48827994e+00\n",
      "    4.96789277e-01  2.05113888e-02  5.91304898e-02]\n",
      "  [-5.62501729e-01 -5.55974245e-02 -8.81470293e-02  4.07052934e-01\n",
      "    2.97979355e-01 -2.54812241e-01 -1.08870387e+00 -4.56115007e-02\n",
      "    1.16504860e+00 -7.22368211e-02 -5.22914946e-01  3.82854640e-01\n",
      "    3.31940800e-01  6.40683293e-01 -4.28141356e-02 -7.09821463e-01\n",
      "    4.95783091e-01  8.52950096e-01  1.12193978e+00  2.17484683e-01\n",
      "    5.79635203e-01  7.41665244e-01  6.33399427e-01]\n",
      "  [ 1.83508620e-01 -3.29243124e-01  6.56942874e-02  9.75765944e-01\n",
      "    3.01737607e-01 -3.06836039e-01  6.64309859e-01 -5.54676056e-01\n",
      "    1.65321663e-01 -7.71360099e-02 -3.45827460e-01  6.97497308e-01\n",
      "   -1.04036108e-02 -3.47737968e-01 -1.22311510e-01 -6.72395110e-01\n",
      "    4.66488034e-01  9.36531425e-02 -1.25685966e+00  4.75568086e-01\n",
      "   -8.32659602e-02 -4.55625296e-01 -2.75531076e-02]]]\n"
     ]
    }
   ],
   "source": [
    "print(grad_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "\n",
      "\n",
      "\n",
      "True\n",
      "True\n",
      "True\n",
      "\n",
      "\n",
      "\n",
      "True\n",
      "True\n",
      "True\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for case in fc_cases:\n",
    "\n",
    "    weight = case['weight']\n",
    "    out_c, in_c = weight.shape\n",
    "    bias = case['bias']\n",
    "    x = case['x'].astype(np.float32)\n",
    "    out = case['out']\n",
    "    grad_output = case['grad_output']\n",
    "    grad_x = case['grad_x']\n",
    "    grad_w = case['grad_w']\n",
    "    grad_b = case['grad_b']\n",
    "    \n",
    "    fc = FullyConnected(d_in=in_c, d_out=out_c)\n",
    "    fc.W = weight\n",
    "    fc.b = bias\n",
    "    test_out = fc(x)\n",
    "    dv_x, dv_W, dv_b = fc.backward(x, grad_output)\n",
    "    \n",
    "    #self.assertTrue(np.allclose(out, test_out, rtol=0.0001))\n",
    "\n",
    "    print(np.allclose(grad_x, dv_x, rtol=0.001))\n",
    "    print(np.allclose(grad_w, dv_W))\n",
    "    print(np.allclose(grad_b, dv_b))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "\n",
      "\n",
      "True \n",
      "\n",
      "\n",
      "True \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for case in max_pool_cases:\n",
    "\n",
    "    kernel = (case['kernel'], case['kernel'])\n",
    "    stride = case['stride']\n",
    "    pad = case['pad']\n",
    "    x = case['x']\n",
    "\n",
    "    out = case['out']\n",
    "    grad_output = case['grad_output']\n",
    "    grad_x = case['grad_x']\n",
    "\n",
    "    max_pool = MaxPool2D(kernel_size=kernel, stride=stride, padding=pad)\n",
    "    test_out = max_pool(x)\n",
    "    dv_x = max_pool.backward(x, grad_output)\n",
    "    \n",
    "    print(np.allclose(grad_x, dv_x, rtol=0.0001), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14866087  0.          0.         -1.75294259  0.          0.        ]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[ 0.          0.          0.          0.         -0.55981082  0.        ]\n",
      "[ 1.78742021  0.         -0.08431914  0.          0.         -2.06593116]\n",
      "[-0.59099364  0.          0.          0.          0.          0.        ]\n",
      "[ 0.         -1.67617209 -2.48737401  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(dv_x[0][0][:6])\n",
    "print(dv_x[0][1][:6])\n",
    "print(dv_x[0][2][:6])\n",
    "print(dv_x[0][3][:6])\n",
    "print(dv_x[0][4][:6])\n",
    "print(dv_x[0][5][:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14866087  0.40237263 -0.82060426 -1.334711    1.0564412   0.13685726]\n",
      "[ 0.5318551   0.97044003 -1.5117408  -1.0416868  -0.937418    0.7219324 ]\n",
      "[ 1.4502536   0.3266159  -0.1045112   0.09457997 -1.1984186   0.4902077 ]\n",
      "[-0.1946885   0.17932318 -1.3813751  -1.1188244   0.33398527  0.90224385]\n",
      "[-0.59099364 -1.9334221  -0.85108024 -0.7435231   1.1538576   0.01682013]\n",
      "[ 0.24902421 -0.1710974  -1.6362938   1.0555542   0.32565504  0.9463995 ]\n"
     ]
    }
   ],
   "source": [
    "print(grad_output[0][0][:6])\n",
    "print(grad_output[0][1][:6])\n",
    "print(grad_output[0][2][:6])\n",
    "print(grad_output[0][3][:6])\n",
    "print(grad_output[0][4][:6])\n",
    "print(grad_output[0][5][:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14866087  0.          0.         -1.7529426   0.          0.        ]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[ 0.         0.         0.         0.        -0.5598108  0.       ]\n",
      "[ 1.7874203   0.         -0.08431911  0.          0.         -2.065931  ]\n",
      "[-0.59099364  0.          0.          0.          0.          0.        ]\n",
      "[ 0.        -1.6761721 -2.487374   0.         0.         0.       ]\n"
     ]
    }
   ],
   "source": [
    "print(grad_x[0][0][:6])\n",
    "print(grad_x[0][1][:6])\n",
    "print(grad_x[0][2][:6])\n",
    "print(grad_x[0][3][:6])\n",
    "print(grad_x[0][4][:6])\n",
    "print(grad_x[0][5][:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.769817   -1.1600094   0.39855713  2.5746279   0.2757979   0.61031055]\n",
      "[-1.2590202  -0.02713936  0.04868459 -0.19278368  0.51870173 -1.8024259 ]\n",
      "[-0.8047651  -0.8062368   0.16242757 -0.93263453  0.61033213 -0.00504397]\n",
      "[ 1.6493801   0.24222896  0.25751153 -1.067929   -0.25932866  0.7788012 ]\n",
      "[ 1.1260225  -0.74210197 -0.26923501 -1.8268266  -0.47851646 -0.6956416 ]\n",
      "[-0.2544994   0.5801176   0.21740314 -1.3613878   0.16488637 -0.04285244]\n"
     ]
    }
   ],
   "source": [
    "print(x[0][0][:6])\n",
    "print(x[0][1][:6])\n",
    "print(x[0][2][:6])\n",
    "print(x[0][3][:6])\n",
    "print(x[0][4][:6])\n",
    "print(x[0][5][:6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
